## üéß Bluetooth Speaker with Microphone for ChatGPT Web Voice Interaction

This project implements a **Bluetooth audio device** using the **ESP32 microcontroller**, functioning as both a **Bluetooth speaker** and **microphone**. The ESP32 connects to a phone or computer via **Classic Bluetooth**, enabling two-way voice interaction with **ChatGPT web or app interfaces** that support voice input/output.

### ‚úÖ System Overview

- **Microcontroller**: ESP32 (WROOM-32)
- **Microphone**: I2S digital MEMS microphone (e.g., INMP441)
- **Speaker**: I2S amplifier (MAX98357A)
- **Bluetooth Profile**: A2DP Sink (audio in) + possible HFP/AG workaround (for mic)
- **User Device**: Phone or laptop running **ChatGPT Web or App**
- **No Internet or Cloud on ESP32** ‚Äî ESP32 only handles audio I/O

---

### üîÅ Flowchart of Voice Interaction

```
       +--------------------+
       |   ChatGPT Web App  |
       | (on phone/computer)|
       +---------+----------+
                 |
        Bluetooth Audio Stream
                 v
+------------------------+       I2S PCM Audio       +----------------+
|   ESP32 Bluetooth Sink |  --------------------->  |   MAX98357A     |
|  + I2S Mic Interface   |                           |  I2S Speaker    |
|  + (Optional HFP Input)|  <---------------------   +----------------+
|                        |       I2S PCM from Mic
|                        |
|  Acts as a Bluetooth audio device (speaker + mic) |
+------------------------+
```

---

### üõ†Ô∏è Features

- **Acts like a Bluetooth headset** (mic + speaker) when paired with a phone or laptop
- Allows real-time voice interaction with ChatGPT via browser or app
- Captures microphone input via I2S and plays back ChatGPT's voice via speaker
- Entirely local ‚Äî **no internet or cloud communication from ESP32**

---

### ‚úÖ Tested Workflow

| Step | Description |
|------|-------------|
| 1Ô∏è‚É£ | ESP32 is powered up and begins Bluetooth pairing |
| 2Ô∏è‚É£ | User connects phone/computer to "ESP32_Speaker" via Bluetooth |
| 3Ô∏è‚É£ | User opens [ChatGPT Web](https://chat.openai.com) with voice enabled |
| 4Ô∏è‚É£ | Microphone input is captured by ESP32 and sent to device |
| 5Ô∏è‚É£ | ChatGPT replies with audio, played back via the ESP32's speaker |

---

### ‚ö†Ô∏è Limitations

- Only **ESP32** supports Classic Bluetooth (A2DP).  
  **ESP32-S3, C3, S2** do **not** support Bluetooth audio.
- Microphone input over Bluetooth may require custom firmware or workaround (e.g., HFP is limited in Arduino framework).
- Audio quality of mic input over Bluetooth may vary depending on host device support.

---

### ‚ùó Challenges Faced

| Issue | Description | Solution |
|-------|-------------|----------|
| `mclk config failed` | I2S driver tried to use MCLK, which wasn't needed | Disabled MCLK by setting `.mclk_io_num = I2S_PIN_NO_CHANGE` |
| Sketch too big | Flash space exceeded with A2DP libraries | Switched to ‚ÄúNo OTA (2MB App)‚Äù partition scheme |
| Compatibility issues | ESP32-S3/C3 didn‚Äôt support A2DP | Restricted implementation to ESP32-WROOM boards |
| Mic over Bluetooth | Limited support for mic-to-host Bluetooth profiles | Used workaround with I2S mic + test server or external tools |

---

### üß™ Test Results

| Component | Status |
|----------|--------|
| Bluetooth Audio Out (Speaker) | ‚úÖ Working |
| I2S Speaker Output (MAX98357A) | ‚úÖ Clear Audio |
| I2S Mic Input (INMP441) | ‚úÖ Captured Voice |
| Connection to ChatGPT Web via Phone | ‚úÖ Functional |
| ESP32 ‚Üî Bluetooth ‚Üî ChatGPT voice chat | ‚úÖ Fully tested |




##
##

## Enhanced Version (but failed)



## üåê ESP32 as Front-End with WebSocket Communication to Backend Server

This project implements a **real-time audio streaming device** using the **ESP32 microcontroller**, functioning as both a **microphone** and **speaker** interface. The ESP32 establishes a **WebSocket connection** to a backend server, enabling two-way voice interaction with **OpenAI's Whisper and TTS services** for speech recognition and synthesis.

### ‚úÖ System Overview

- **Microcontroller**: ESP32 (WROOM-32)
- **Microphone**: INMP441 I2S digital MEMS microphone
- **Speaker**: I2S DAC for audio output
- **Connection**: WebSocket over WiFi
- **Protocol**: Binary WebSocket frames for audio, text frames for control
- **Server**: Backend processing server at 192.168.50.62:3000
- **Audio Services**: OpenAI Whisper (speech-to-text) and TTS (text-to-speech)

---

### üîÅ Flowchart of Audio Communication

```
+----------------+                  +----------------+                  +----------------+
|                |   WiFi/WebSocket |                |     Processing   |                |
|  ESP32 Device  | <--------------> | Backend Server | <--------------> |  OpenAI API    |
|  (Mic+Speaker) |      Audio       |                |                  | Whisper & TTS  |
+----------------+                  +----------------+                  +----------------+
       ^                                   ^
       |                                   |
    I2S Audio                         Transcription and
    Capture/Playback                  Speech Synthesis
```

---

### üõ†Ô∏è Features

- **Real-time bidirectional audio streaming** via WebSocket protocol
- **Dual-core processing** utilizing both ESP32 cores for parallel audio tasks
- **I2S digital audio interface** for high-quality sound capture and playback
- **Format conversion** between 16-bit PCM and 32-bit float audio formats
- **Persistent WebSocket connection** with automatic reconnection handling
- **Integration with OpenAI services** for intelligent voice interaction

---

### üíª Dual-Core Implementation

The ESP32's dual-core architecture is leveraged to optimize audio processing performance:

```cpp
// Create tasks for dual-core processing
xTaskCreatePinnedToCore(
  microphoneTask,     // Task function
  "MicrophoneTask",   // Name
  8192,               // Stack size
  NULL,               // Parameters
  1,                  // Priority
  &micTaskHandle,     // Task handle
  0                   // Run on Core 0
);

xTaskCreatePinnedToCore(
  speakerTask,        // Task function
  "SpeakerTask",      // Name
  8192,               // Stack size
  NULL,               // Parameters
  1,                  // Priority
  &speakerTaskHandle, // Task handle
  1                   // Run on Core 1
);
```

This separation of tasks allows:
- **Core 0**: Dedicated to microphone audio capture and WebSocket transmission
- **Core 1**: Manages incoming audio data and speaker output
- **Thread-safe communication**: Uses mutex-protected buffers for data exchange
- **Independent processing**: Audio input and output operate without blocking each other

---

### üìã Implementation Details

| Component | Implementation |
|-----------|----------------|
| WiFi Connection | Connects to network "ISC-SG" for server access |
| WebSocket Client | Connects to ws://192.168.50.62:3000/audio endpoint |
| Audio Capture | 16kHz, 16-bit PCM input from INMP441 on I2S_NUM_1 |
| Audio Playback | 32kHz, 16-bit PCM output to speaker on I2S_NUM_0 |
| Task Distribution | Core 0: Microphone task, Core 1: Speaker task |
| Control Protocol | "START_LISTENING", "STOP_LISTENING", "START_SPEAKING", "STOP_SPEAKING" |
| Speech Recognition | Captured audio sent to server, processed by OpenAI Whisper API |
| Speech Synthesis | Text responses converted to speech using OpenAI TTS API |

---

### ‚ö†Ô∏è Challenges Faced

| Issue | Description | Solution |
|-------|-------------|----------|
| Format Incompatibility | Server expected 32-bit float, but speaker needed 16-bit PCM | Implemented format conversion with appropriate scaling |
| Task Synchronization | Microphone and Speaker tasks needed coordination | Used mutex-protected shared buffers and status flags |
| Empty Files on Server | Server received audio but couldn't process it for Whisper | Audio format mismatch investigation; file format needs adjustment |
| I2S Configuration | Initial I2S setup issues for both mic and speaker | Properly configured I2S parameters for both ports |
| OpenAI Format Requirements | Whisper expects specific audio format (PCM_F32LE) | Ensured correct format conversion before transmission |

---

### üß™ Test Results

| Component | Status |
|-----------|--------|
| WiFi Connection | ‚úÖ Stable |
| WebSocket Communication | ‚úÖ Reliable connection established |
| Audio Transmission (ESP32‚ÜíServer) | ‚úÖ Data packets sent successfully |
| Audio Reception (Server‚ÜíESP32) | ‚úÖ Binary frames received |
| Audio Playback | ‚úÖ Confirmed working with test tones |
| Dual-Core Performance | ‚úÖ Successfully distributing processing across cores |
| Server Processing | ‚ö†Ô∏è Empty files received by Whisper - format adjustment needed |

---

### üîÑ Communication Flow

1. **ESP32 connects** to WiFi network and establishes WebSocket connection
2. **Server sends** "START_LISTENING" when ready to receive audio
3. **Microphone task (Core 0)** captures audio via I2S interface
4. **Audio data** is transmitted as binary WebSocket frames to server
5. **Server processes** audio with OpenAI Whisper for speech recognition
6. **Response text** is generated and converted to speech using OpenAI TTS
7. **Audio response** is sent back to ESP32 as binary WebSocket frames
8. **Speaker task (Core 1)** plays received audio through the I2S DAC

---

### üéµ Testing & Verification

The audio output functionality has been successfully verified through test tones sent from the server to the ESP32. The speaker produces clear and audible sound, confirming that the WebSocket communication, binary data reception, and I2S speaker output are all functioning correctly.

The dual-core implementation shows significant benefits in maintaining consistent audio streaming by preventing microphone and speaker operations from interfering with each other. This architecture is particularly important for real-time applications where audio latency must be minimized.

The microphone capture and transmission appear to work based on packet transmission metrics, but the server currently receives empty or improperly formatted audio files. This suggests that while the ESP32 front-end is correctly implementing its portion of the audio pipeline, adjustments are needed in either the data format or the server's processing of received audio data to enable full bidirectional communication with the OpenAI audio services.